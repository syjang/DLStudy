{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = np.array([[0,0],[0,1],[1,0],[1,1]],dtype = np.float32)\n",
    "y_data = np.array([[0],[1],[1],[0]],dtype = np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32)\n",
    "Y = tf.placeholder(tf.float32)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([2,2]),name='weight1')\n",
    "b1 = tf.Variable(tf.random_normal([2]),name='bias1')\n",
    "layer1 = tf.sigmoid(tf.matmul(X,W1)+b1)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([2,1]),name='weight2')\n",
    "b2 = tf.Variable(tf.random_normal([1]),name='bias2')\n",
    "\n",
    "hypothesis = tf.sigmoid(tf.matmul(layer1,W2)+b2)\n",
    "\n",
    "cost = -tf.reduce_mean(Y*tf.log(hypothesis) + (1-Y)*tf.log(1-hypothesis))\n",
    "train = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = tf.cast(hypothesis > 0.5 ,dtype =tf.float32)\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted,Y), dtype =tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.695465 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "100 0.687831 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "200 0.685249 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "300 0.681661 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "400 0.676791 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "500 0.670411 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "600 0.662357 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "700 0.652522 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "800 0.640855 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "900 0.627397 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1000 0.612334 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1100 0.596009 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1200 0.578857 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1300 0.561272 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1400 0.543486 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1500 0.525486 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1600 0.506979 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1700 0.487406 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1800 0.466032 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "1900 0.442201 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2000 0.415679 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2100 0.386845 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2200 0.356566 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2300 0.325894 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2400 0.295844 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2500 0.267269 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2600 0.240789 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2700 0.216769 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2800 0.19533 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "2900 0.176411 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3000 0.159834 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3100 0.145361 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3200 0.132737 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3300 0.121714 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3400 0.112067 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3500 0.103597 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3600 0.0961335 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3700 0.0895294 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3800 0.0836618 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "3900 0.0784266 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4000 0.0737365 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4100 0.0695179 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4200 0.0657088 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4300 0.0622567 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4400 0.0591173 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4500 0.0562525 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4600 0.05363 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4700 0.0512223 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4800 0.0490053 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "4900 0.0469584 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5000 0.0450639 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5100 0.043306 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5200 0.0416712 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5300 0.0401476 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5400 0.0387246 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5500 0.0373931 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5600 0.0361448 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5700 0.0349725 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5800 0.0338697 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "5900 0.0328305 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6000 0.03185 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6100 0.0309233 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6200 0.0300463 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6300 0.0292153 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6400 0.0284268 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6500 0.0276778 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6600 0.0269654 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6700 0.0262871 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6800 0.0256406 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "6900 0.0250237 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7000 0.0244346 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7100 0.0238715 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7200 0.0233326 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7300 0.0228165 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7400 0.0223218 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7500 0.0218474 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7600 0.0213919 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7700 0.0209543 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7800 0.0205335 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "7900 0.0201287 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8000 0.019739 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8100 0.0193635 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8200 0.0190016 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8300 0.0186524 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8400 0.0183155 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8500 0.0179901 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8600 0.0176756 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8700 0.0173715 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8800 0.0170775 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "8900 0.0167929 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9000 0.0165173 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9100 0.0162503 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9200 0.0159916 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9300 0.0157407 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9400 0.0154973 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9500 0.0152611 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9600 0.0150318 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9700 0.0148091 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9800 0.0145927 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "9900 0.0143823 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "10000 0.0141777 [[-0.64010668]\n",
      " [ 0.3862288 ]]\n",
      "\n",
      "hyp [[ 0.01126865]\n",
      " [ 0.98728883]\n",
      " [ 0.98734272]\n",
      " [ 0.01965195]] \n",
      "cost [[ 0.]\n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 0.]] \n",
      "acc 1.0\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for step in range(10001):\n",
    "        sess.run(train,feed_dict={X: x_data, Y:y_data})\n",
    "        if step %100 == 0:\n",
    "            print(step,sess.run(cost,feed_dict={X:x_data, Y:y_data}),sess.run(W))\n",
    "        \n",
    "    h,c,a =sess.run([hypothesis,predicted,accuracy],feed_dict={X:x_data ,Y: y_data})\n",
    "    print(\"\\nhyp\" ,h ,\"\\ncost\",c ,\"\\nacc\",a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
