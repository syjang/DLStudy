{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "from keras.datasets import imdb\n",
    "from keras import layers, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data:\n",
    "    def __init__(self, max_features =20000 ,maxlen =80):\n",
    "        (x_train,self.y_train),(x_test,self.y_test) = imdb.load_data(num_words=max_features)\n",
    "        self.x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
    "        self.x_test = sequence.pad_sequences(x_test,maxlen=maxlen)        \n",
    "        \n",
    "class RNN_LSTM(models.Model):\n",
    "    def __init__(self, max_features , maxlen):\n",
    "        x= layers.Input((maxlen,))\n",
    "        h = layers.Embedding(max_features,128)(x)\n",
    "        h = layers.LSTM(128 , dropout=0.2 ,recurrent_dropout=0.2)(h)\n",
    "        y = layers.Dense(1,activation='sigmoid')(h)\n",
    "        super().__init__(x,y)\n",
    "        self.compile(loss='binary_crossentropy' , optimizer ='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Machine:\n",
    "    def __init__(self,max_features =20000,maxlen =80):\n",
    "        self.data = Data(max_features, maxlen)\n",
    "        self.model = RNN_LSTM(max_features, maxlen)\n",
    "        \n",
    "    def run(self, epochs=3, batch_size = 32):\n",
    "        data = self.data\n",
    "        model = self.model\n",
    "        print('Training state')\n",
    "        print('================')\n",
    "        model.fit(data.x_train,data.y_train,batch_size =batch_size,\n",
    "                  epochs = epochs,\n",
    "                  validation_data=(data.x_test,data.y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training state\n",
      "================\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/3\n",
      "25000/25000 [==============================] - 104s 4ms/step - loss: 0.4594 - acc: 0.7842 - val_loss: 0.3926 - val_acc: 0.8272\n",
      "Epoch 2/3\n",
      "25000/25000 [==============================] - 100s 4ms/step - loss: 0.2982 - acc: 0.8784 - val_loss: 0.3856 - val_acc: 0.8297\n",
      "Epoch 3/3\n",
      "25000/25000 [==============================] - 100s 4ms/step - loss: 0.2214 - acc: 0.9127 - val_loss: 0.4298 - val_acc: 0.8313\n"
     ]
    }
   ],
   "source": [
    "m = Machine()\n",
    "m.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 20s 785us/step\n",
      "0.83128\n",
      "0.4298180000591278\n"
     ]
    }
   ],
   "source": [
    "score ,acc = m.model.evaluate(m.data.x_test, m.data.y_test,batch_size=32)\n",
    "print(acc)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
