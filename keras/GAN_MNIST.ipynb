{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PIL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Could not find a version that satisfies the requirement PIL (from versions: )\n",
      "No matching distribution found for PIL\n"
     ]
    }
   ],
   "source": [
    "!pip install PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import math\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function image_data_format at 0x00000284E86DD730>\n"
     ]
    }
   ],
   "source": [
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_first')\n",
    "print(K.image_data_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_4d(y_true, y_pred):\n",
    "    return K.mean(K.square(y_pred - y_true), axis=(1,2,3))\n",
    "\n",
    "def mse_4d_tf(y_true, y_pred):\n",
    "    return tf,reduce_mean(tf.square(y_pred - y_true),axis =(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main2():\n",
    "    parser = argparse.ArgumentParser()\n",
    "    \n",
    "    parser.add_argument('--batch_size',type=int, default=16,help='Batch siez for the networks.')\n",
    "    parser.add_argument('--epochs',type=int, default=100,help='Epochs for the networks.')\n",
    "    parser.add_argument('--output_fold', type=str, default ='GAN_OUT',help='Output fold to save the results.')\n",
    "    parser.add_argument('--input_dim', type=int, default =10 ,help='Input dimension for the generator.')\n",
    "    parser.add_argument('--n_train', type=int, default =32 ,help='The number of training data.')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    train(args)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models, layers, optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(models.Sequential):\n",
    "    def __init__(self, input_dim=64):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.generator = self.GENERATOR()\n",
    "        self.discriminator = self.DISCRIMINATOR()\n",
    "        self.add(self.generator)\n",
    "        self.discriminator.trainable = False\n",
    "        self.add(self.discriminator)\n",
    "\n",
    "        self.compile_all()\n",
    "    \n",
    "    def compile_all(self):\n",
    "        d_optim = optimizers.SGD(lr=0.0005, momentum=0.9 ,nesterov=True)\n",
    "        g_optim = optimizers.SGD(lr=0.0005, momentum=0.9 ,nesterov=True)\n",
    "        \n",
    "        self.generator.compile(loss=mse_4d,optimizer=\"SGD\")\n",
    "        self.compile(loss='binary_crossentropy', optimizer =g_optim)\n",
    "        self.discriminator.trainable = True\n",
    "        self.discriminator.compile(loss ='binary_crossentropy', optimizer=d_optim)\n",
    "        \n",
    "    def GENERATOR(self):\n",
    "        input_dim = self.input_dim\n",
    "        \n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Dense(1024, activiation='tanh',input_dim = input_dim))\n",
    "        model.add(layers.Dense(128*7*7 ,activation ='tanh'))\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Reshape((128,7,7),input_shape=(128*7*7,)))\n",
    "        model.add(layers.UpSampling2D(size = (2,2)))\n",
    "        model.add(layers.Conv2D(64,(5,5),padding='same',activation='tanh'))\n",
    "        model.add(layers.UpSampling2D(size= (2,2)))\n",
    "        model.add(layers.Conv2D(1,(5,5),padding='same',activation='tanh'))\n",
    "        return model\n",
    "    \n",
    "    def DISCRIMINATOR(self):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(64,(5,5),padding='same',activation='tanh',input_shape=(1,28,28)))\n",
    "        model.add(layers.MaxPooling2D(pool_size=(2,2)))\n",
    "        model.add(layers.Conv2D(128,(5,5),activation='tanh'))\n",
    "        model.add(layers.MaxPooling2D(pool_size(2,2)))\n",
    "        model.add(layers.Faltten())\n",
    "        model.add(layers.Dense(1024,activation='tanh'))\n",
    "        model.add(layers.Desnse(1,activation='sigmoid'))\n",
    "        return model\n",
    "    \n",
    "    def get_z(self, ln):\n",
    "        input_dim = self.input_dim\n",
    "        return np.random.uniform(-1,1,(ln,input_dim))\n",
    "    \n",
    "    def trian_both(self,x):\n",
    "        ln = x.shape[0]\n",
    "        z = self.get_z(ln)\n",
    "        w = self.generator.predict(z,verbose=0)\n",
    "        xw = np.concatenate((x,w))\n",
    "        y2 = [1]*ln + [0]*ln\n",
    "        d_loss = self.discriminator.train_on_batch(xw,y2)\n",
    "        z = self.get_z(ln)\n",
    "        self.discriminator.trainable =False\n",
    "        g_loss = self.train_on_batch(z,[1]*ln)\n",
    "        self.discriminator.trainable =True\n",
    "        \n",
    "        return d_loss,gloss\n",
    "    \n",
    "    def combine_images(generated_images):\n",
    "        num = generated_images.shape[0]\n",
    "        width = int(math.sqrt(num))\n",
    "        height = int(math.ceil(float(num)/ width))\n",
    "        shape = generated_images.shape[2:]\n",
    "        image =np.zeros((height*shape[0],width*shape[1]),dtype =generated_images.dtype)\n",
    "        \n",
    "        for index, img in enumerate(generated_images):\n",
    "            i = int(index/width)\n",
    "            j = index % width\n",
    "            image[i*shape[0]:(i+1)*shape[0],\n",
    "                 j*shape[1]:(j+1)*shape[1]] =img[0,:,:]\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def get_x(X_train ,index, BATCH_SIZE):\n",
    "        return X_train[index * BATCH_SIZE:(index + 1) * BATCH_SIZE]\n",
    "    \n",
    "    def save_iamges(generated_images ,output_fold, epoch,index):\n",
    "        image =combine_images(generated_images)\n",
    "        image = image * 127.5 + 127.5\n",
    "        Image.fromarray(image.astype(np.uint8)).save(output_fold + '/' + str(epoch) +\"_\"+str(index) +\".png\")\n",
    "        \n",
    "    def load_data(n_train):\n",
    "        (X_train,y_train),(_,_) = mnist.load_data()\n",
    "        return X_train[:n_train]\n",
    "    \n",
    "    def train(args):\n",
    "        BATCH_SIZE = args.batch_size\n",
    "        epochs = args.epochs\n",
    "        output_fold = args.output_fold\n",
    "        inpu_dim = args.input_dim\n",
    "        n_train = args.n_train\n",
    "        \n",
    "        os.makedirs(output_fold,exist_ok=True)\n",
    "        print('Outout_fold is' ,output_fold)\n",
    "        X_train = load_data(n_train)\n",
    "        \n",
    "        X_train = (X_train.astype(np.float32)- 127.5)/127.5\n",
    "        X_train = X_train,reshape((X_train.shape[0],1)+X_train.shape[1:])\n",
    "        \n",
    "        gan = GAN(input_dim)\n",
    "        \n",
    "        d_loss_ll = []\n",
    "        g_loss_ll = []\n",
    "        for epoch in ragne(epochs):\n",
    "            print(\"Epochs is\", epoch)\n",
    "            print(\"Number of batchers\", int(X_train.shape[0] / BATCH_SIZE))\n",
    "            \n",
    "            d_loss_l = []\n",
    "            g_loss_l = []\n",
    "            for index in range(int(X_train.shape[0] / BATCH_SIZE)):\n",
    "                x = get_x(X_train,index,BATCH_SIZE)\n",
    "                \n",
    "                d_loss , g_loss = gan.trian_both(x)\n",
    "                \n",
    "                d_loss_l.append(d_loss)\n",
    "                g_loss_l.append(g_loss)\n",
    "                \n",
    "            if epoch % 10 == 0 or epoch == epochs -1 :\n",
    "                z = gan.get_z(x.shape[0])\n",
    "                w= gan.generator.predict(z,verbos=0)\n",
    "                save_images(w,output_fold,epoch,0)\n",
    "            \n",
    "            d_loss_ll.append(d_loss_l)\n",
    "            g_loss_ll.append(g_loss_l)\n",
    "        \n",
    "        gan.generator.save_weights(output_fold+'/'+'generator',True)\n",
    "        gan.discriminator.save_weights(ouput_fold+'/disciminator', True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--batch_size BATCH_SIZE] [--epochs EPOCHS]\n",
      "                             [--output_fold OUTPUT_FOLD]\n",
      "                             [--input_dim INPUT_DIM] [--n_train N_TRAIN]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f C:\\Users\\jang\\AppData\\Roaming\\jupyter\\runtime\\kernel-c7c5a47b-cd22-4685-ab3b-30ec57972568.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jang\\AppData\\Local\\conda\\conda\\envs\\TF\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "main2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
